<done>
https://web.microsoftstream.com/video/da22e7c5-c273-47d7-8147-606d5fdd505f

listen up to 30 minutes  starting from 29 minutes is good

目的: 利用一個train model (with label data, offline)  來預估在一個unlabel 的data set(也就是類似eye-off data but in production) 的performance 多好 by estimator

ye-yi 問題?

但是這樣在cold start 有幫助

但是一班的model1 -> model2 有幫助嗎(most cases)? 
   yes . 因為model1 model2 你可以跑一樣的prod duction traffic eye off data, 所以你可以知道model2 有沒有更好
   但是你只能知道bullpakr number , 沒有辦法pie/ bucketized detail
   model1 : 81%
   model2 : 82%
   you cannot say 82% model2 is better than 81% because of eye-off data
   

only precision cares here
so consider those 
1>alignment error
tag extra word or lack of one work
2>over tagger error
no tag => tag
3>
slot type error
<wrong type> error
? 但是第三個case 就每個slot 來講  也是negative case 也可以算是recall 我猜?


26:14
for this snorkel pipeline
does it amplify the issue that that two judgesr judge them differently or in fact it will help reduce? 
ans: for frequency one, it will reply on context pattern analysis(pulled by statistical result)
so it should help
 ? but for infrequenct case it probably will not help much.


27:27
sample idea by walking through examples
<message> slot , open text
  這邊因該是用eye-on data 來模擬狀況
  ? 如果沒有pattern 只有search query , very short 感覺不太能用
  ? 這跟在 train  的時候  加到pcfg or 額外的pattern for feature 似乎公用很接近
  
  'Message to'
  'Message'
  snorkel backend 會建立這種的correlated function 然後來改善result
  ? 可能要到實際的detail 才有意義
  
  ye-yi 問題
  如果model 並沒有做好  true precision 沒有很高  這樣的加signal 有用嗎?
  (這個問題在colde start 會發生的)
  ans: 
  這種實驗還沒做  但是因為precision 低, fp 很多  反而estimated precision 可以更focus  extra pattern 來幫助model 解決這些wrong prediction
  
  ?這個還不太懂
  另外  如果precision model 已經很高  把所有的points 都assign positive 就可以逼近這個precision model 也不太有意義
  
  
  
  
<contact_name>

38:30
above seems promising 但是會有一些其他的結果要注意的嗎?
 eg:
 'message to' 
    的所有case
    有些case 是true positive
    有些case 是false positive
    加進去這些signal 總是會有一些東西是有問題的
    另外pattern 在不同的dataseet 可能不是balance
       ? 這個問題因該是data sampling 的問題  我覺得不用worry
    怎麼解決呢?
    by general principles
    
 general principles
   1> more labels functions are better
   2> uncorreclataed label functions are better
   3> discrimative power
      就是message to 這個case 你要mind 更多個case 避免 選了產生false positve case
      
   4> knowledge base
       lexicion base 但是可能只對contact name 有幫助
       
   5> more data is helpful
   
 for precision estimator
    what metrics being used to do estimation?
      focus on precision space
      
      using those to callcaute metric
      col1: model prediction
      col2: estimator output
         這個因該是snorkel 的
      col3: ground true lable
      p.s each scenrio 要col1 / col2 /col3 輸出
      
      1> estimator accuracy
          true : estimator output == ground true label == 1
          all scenarios 一起算precision
          用來判斷estimator 有多正確
          
          
      2> true precision
          true : model output == ground true label == 1
          all scenarios 一起算precision
          
      3> estimated precision
          這個是當作沒有ground truth label
          所以適用model output v.s estimator output 
          true : model output == estimator output
          == 1
          all scenarios 一起算precision
          
      goal : "estimated precision" should be as close as "true precision"
      set "estimator error" = "true precision" - "estimated precision"
      ee
         根據圖的解釋 只跟兩個 cases 有關西
         一個case 增加error 一個case 減少error
         (考慮precision space)
         這個case 比較難想
         增加estimator error 
             model output == 1  
             estimator output  == 0
             ground true label == 1
         減少estimator error
             p.s 這個case 
             model output == 1  
             estimator output  == 1
             ground true label == 0     
             
             
       in conclusion:
                  希望"estimated accuracy" 要高   "estimator error" 要在一個可以accpetable 的range
         
      

bridge the gap?
       step1: <covered in this lecture>
           focus on what current model does not do well  (而不是利用estimate error 來幫助build another model)
       step2: <not covered in this lecture>
           replying on more external signals to help build another model
           
           
47:25
with above step1 and estimated accuracy . estimator error, how does it perform in our evaluation set?
    
    
    observation
    message slot
       most error align errors
       BERT might be a way to help this . need to wait haoda's experiment
       
    contact_name
       lexicon is the key( you can treat multiple grams as a single lexicon as well) and we rely on n-gram features
       p.s both these can be applied to other slots
       this does make sense
       
    destination platform
       most from inconsistency slot annotation
       file_action_context 跟這個很像
       
     relationship_name
       跟contact_name 常常衝突
       現在files domain 沒有  以後可以參考
       
   
   
 50:00
 目前test data 沒有很多  用deep learning model  用處不大
 但是以後因該是有幫助的?
 
 51:00
 current work
   aether pipeline
   can support label data and unlabel data
   
   
 52:00
 next step
   more lingustic features
   embedding feautre
      ? 這個因該是可以想一想
      
      
 question
    q: here focus on slot precision can it be extend to domain and intent?
    YES
    q: how to deal with cold start?
    brainstorm patterns to generate  (因為是eye off 我猜  只能這樣做)
    ? search world i do not think it works
    
    q: how about the reacll
      因為你可以直接不做prediciton 這樣predition 跟recall 都可以很好
      recall problem is harder
      ? 不懂為啥
      
    q: 認為estimator 的erorr 大部分不是來自於 align error 而是type error?
       對於type erorr 的detect 能力比較強
       但是可能實際model 的error  大部分來自於align error
       可能要想想  怎麼extend 來cover
       沒有answer 因為影片已經結束....
    
   
   
   
   

